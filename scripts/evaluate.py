"""
evaluate.py ‚Äî Phase 5 : √âvaluation sur benchmarks.

√âvalue le mod√®le Student sur :
- NYU-Depth V2 (654 images, indoor)
- KITTI (697 images, outdoor/driving)

Compare avec les r√©sultats officiels de DAv2-Small :
    NYU-D : AbsRel=0.053, Œ¥1=0.992
    KITTI : AbsRel=0.041, Œ¥1=0.993

Objectifs :
- Minimum : AbsRel < 0.08, Œ¥1 > 0.95 (gap < 30%)
- Moyen   : gap < 20% vs mod√®le officiel
- Excellent: gap < 20% + ablation studies

Usage :
    python scripts/evaluate.py \
        --checkpoint outputs/checkpoints/best_model.pt \
        --nyu_dir datasets/benchmarks/nyu_depth_v2 \
        --kitti_dir datasets/benchmarks/kitti \
        --output_dir outputs/evaluation
"""

import sys
import json
import argparse
from pathlib import Path

import torch

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.models.student import StudentModel
from src.evaluation.benchmark import BenchmarkEvaluator
from src.evaluation.metrics import DepthMetrics
from src.utils.helpers import get_device, set_seed


def parse_args():
    parser = argparse.ArgumentParser(description="Phase 5 ‚Äî √âvaluation sur benchmarks")
    parser.add_argument("--checkpoint", type=str, required=True,
                        help="Chemin vers le checkpoint du Student")
    parser.add_argument("--backbone", type=str, default="dinov2_vits14",
                        help="Backbone du Student")
    parser.add_argument("--image_size", type=int, default=518,
                        help="Taille de resize")

    # Benchmarks
    parser.add_argument("--nyu_dir", type=str, default=None,
                        help="Chemin vers NYU-Depth V2 test")
    parser.add_argument("--kitti_dir", type=str, default=None,
                        help="Chemin vers KITTI test")

    parser.add_argument("--batch_size", type=int, default=8,
                        help="Batch size pour l'√©valuation")
    parser.add_argument("--output_dir", type=str, default="outputs/evaluation",
                        help="R√©pertoire de sortie des r√©sultats")
    return parser.parse_args()


def main():
    args = parse_args()
    set_seed(42)
    device = get_device()

    print("=" * 60)
    print("Phase 5 : √âvaluation sur benchmarks")
    print("=" * 60)

    # 1. Charger le mod√®le Student
    print("\n--- Chargement du Student ---")
    student = StudentModel(
        backbone_name=args.backbone,
        image_size=args.image_size,
    )
    student.load_checkpoint(args.checkpoint)
    student = student.to(device)
    student.eval()

    params = student.count_parameters()
    print(f"  Param√®tres : {params['total_M']:.1f}M")

    # 2. √âvaluation
    evaluator = BenchmarkEvaluator(
        model=student,
        device=str(device),
        image_size=args.image_size,
    )

    results = evaluator.full_evaluation(
        nyu_dir=args.nyu_dir,
        kitti_dir=args.kitti_dir,
    )

    # 3. Sauvegarder les r√©sultats
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    results_path = output_dir / "benchmark_results.json"
    with open(results_path, "w") as f:
        json.dump(results, f, indent=2)
    print(f"\nR√©sultats sauvegard√©s dans : {results_path}")

    # 4. Tableau r√©capitulatif
    print("\n" + "=" * 60)
    print("R√âCAPITULATIF")
    print("=" * 60)
    print(f"{'Mod√®le':<25} {'AbsRel (NYU)':>14} {'Œ¥1 (NYU)':>10} {'Params':>10}")
    print("-" * 60)
    print(f"{'DAv2-Small (officiel)':<25} {'0.053':>14} {'0.992':>10} {'25M':>10}")

    if "nyu" in results:
        nyu = results["nyu"]
        print(f"{'Notre mod√®le':<25} {nyu['absrel']:>14.4f} {nyu['delta1']:>10.4f} {params['total_M']:>9.1f}M")

        # Gap
        gap_absrel = ((nyu["absrel"] - 0.053) / 0.053) * 100
        gap_delta1 = ((0.992 - nyu["delta1"]) / 0.992) * 100
        print(f"\nGap vs officiel :")
        print(f"  AbsRel : {gap_absrel:+.1f}%")
        print(f"  Œ¥1     : {gap_delta1:+.1f}%")

        # √âvaluation du niveau
        if gap_absrel < 20 and gap_delta1 < 5:
            print("\nüèÜ Excellence (gap < 20%)")
        elif gap_absrel < 30:
            print("\n‚úÖ Objectif moyen atteint (gap < 30%)")
        elif nyu["absrel"] < 0.08 and nyu["delta1"] > 0.95:
            print("\n‚úÖ Objectif minimum atteint")
        else:
            print("\n‚ö† En dessous des objectifs minimum")

    print("\n‚úÖ √âvaluation termin√©e.")


if __name__ == "__main__":
    main()
